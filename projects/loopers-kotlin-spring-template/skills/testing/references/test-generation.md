# Test Case Extraction

This document describes how to extract and generate test cases from spec documents for TDD workflow.

## Role

Test case extraction answers: "What test cases are needed to verify this milestone?"

The output is test skeletons - empty test methods with clear names that describe expected behavior. Implementer fills in
actual test code later.

This enables true TDD: red tests exist before any implementation.

---

## MUST: Decompose Spec Criteria by Class Responsibility

### The Rule

```
SPEC ACCEPTANCE CRITERIA â‰  TEST CASES

Decompose each acceptance criterion by class responsibility.
Place each piece at the appropriate test level.
```

### ğŸš¨ Red Flags

| Thought                                      | Reality                                                                        |
|----------------------------------------------|--------------------------------------------------------------------------------|
| "Spec says X, so test X in this class"       | Ask: Is X this class's responsibility?                                         |
| "One acceptance criterion = one test case"   | Decompose by class responsibility first                                        |
| "Facade test should verify all outcomes"     | Facade verifies orchestration; individual outcomes belong to their owning class |

### Decomposition Example

**Spec**: "When placing an order, points are deducted, stock decreases, and order is created"

| Responsibility          | Class             | Test Level  | What to Verify                            |
|-------------------------|-------------------|-------------|-------------------------------------------|
| Point deduction logic   | Point (domain)    | Unit        | `deduct()` calculates correctly           |
| Stock decrease logic    | Stock (domain)    | Unit        | `decrease()` calculates correctly         |
| Orchestration success   | OrderFacade       | Integration | Scenario completes, DB reflects final state |
| Transaction rollback    | OrderFacade/Service | Integration | All resources restored on failure         |

**Rule**: Domain logic correctness â†’ Unit Test. Scenario outcome in DB â†’ Integration Test.

> If combinations exceed 8, apply unit-test.md Combinatorial Explosion Guide Step 1 to verify responsibility separation first.

---

## Handling Spec-Code Gaps (TDD Essential)

When spec describes functionality NOT YET implemented:

```
Is this a TDD workflow (tests before implementation)?
â”œâ”€â”€ Yes â†’ Generate skeleton for spec requirement (RED phase)
â”‚         The test SHOULD fail until implementation exists
â””â”€â”€ No  â†’ Document the gap, ask for clarification
```

**Key principle**: In TDD, tests are written BEFORE code exists. Generate skeletons for ALL spec requirements, even if
implementation doesn't exist yet.

---

## Test Case Extraction Process

### Step 1: Read Spec References

Read the spec sections specified in the milestone instruction and extract all testable requirements:

- Business rules that must be enforced
- Calculations that must be accurate
- State transitions that must be allowed or prevented
- Error conditions that must be handled
- Numeric constraints and their boundaries (min, max, thresholds)
  â†’ Each boundary produces 3 test values: boundary-1, boundary, boundary+1
- Input dimensions and their equivalence classes
  â†’ Each class produces 1 representative test value
- Multi-condition interaction points
  â†’ Conditions that combine to determine outcomes need systematic combination

### Step 2: Determine Test Level

Determine which level each requirement belongs to (Unit, Integration, Concurrency, Adapter, E2E).

### Step 3: Extract Cases by Level

Follow the extraction patterns in the corresponding level-specific reference file.

### Step 4: Write Test Skeletons

Write each case as a test method following BDD structure:

- `@DisplayName` in Korean describing the behavior
- Given/When/Then comments as implementation hints
- `fail("Not implemented")` in every test body

---

## @Nested Class Organization

Structure @Nested classes by **outcome type**, not by scenario:

```kotlin
@DisplayName("CouponService")
class CouponServiceIntegrationTest {

    @Nested
    @DisplayName("issueCoupon")
    inner class IssueCoupon {
        // âœ… Success cases grouped
        @Test
        fun `assigns coupon when valid code`() {
            ...
        }
        @Test
        fun `assigns coupon when user has other coupons`() {
            ...
        }
    }

    @Nested
    @DisplayName("issueCoupon - ì‹¤íŒ¨")
    inner class IssueCouponFailure {
        // âœ… Failure cases grouped
        @Test
        fun `throws NOT_FOUND when coupon not exists`() {
            ...
        }
        @Test
        fun `throws CONFLICT when already issued`() {
            ...
        }
    }
}
```

**Alternative**: If failure types are distinct and numerous, separate by error type:

```kotlin
@Nested
@DisplayName("issueCoupon - NOT_FOUND")
inner class IssueCouponNotFound { ... }
@Nested
@DisplayName("issueCoupon - CONFLICT")
inner class IssueCouponConflict { ... }
```

---

## Method Naming Convention

Pattern: `[verb phrase] when [condition]`

| Pattern        | Example                                      |
|----------------|----------------------------------------------|
| Success        | `assigns coupon when valid code`             |
| Exception      | `throws NOT_FOUND when coupon not exists`    |
| State change   | `decreases balance when deduct valid amount` |
| Boolean result | `returns true when user has permission`      |

**Not allowed**:

- âŒ `testIssueCoupon` (no condition)
- âŒ `couponIssuedSuccessfully` (no "when")
- âŒ `should assign coupon` (avoid "should")

---

## Test File Scoping

When to create new test file vs extend existing:

| Situation                              | Action                                     |
|----------------------------------------|--------------------------------------------|
| New method on existing class           | Add @Nested to existing test file          |
| Existing file > 500 lines              | Consider splitting by method               |
| New class                              | New test file                              |
| Focused test (concurrency, edge cases) | Separate test file with descriptive suffix |

**File naming examples**:

- `CouponServiceIntegrationTest.kt` - Main integration tests
- `CouponServiceConcurrencyTest.kt` - Concurrency-specific tests
- `CouponIssueLimitIntegrationTest.kt` - Feature-focused tests

---

## Given/When/Then Specificity

Specify **test-relevant** values only. Skip implementation details.

```kotlin
// âœ… GOOD: Concrete values that matter for the test
@Test
fun `throws CONFLICT when already issued`() {
    // Given: userId=1 ì´ë¯¸ couponId=100ì„ ë°œê¸‰ë°›ì€ ìƒíƒœ
    // When: ë™ì¼ userIdë¡œ ë™ì¼ couponId ë°œê¸‰ ìš”ì²­
    // Then: CoreException(ErrorType.CONFLICT) ë°œìƒ
    fail("Not implemented")
}

// âŒ BAD: Too much implementation detail
@Test
fun `throws CONFLICT when already issued`() {
    // Given: User entity (id=1, name="í™ê¸¸ë™", email="test@test.com", createdAt=2025-01-01)
    //        exists in users table, IssuedCoupon entity with 12 fields exists...
    // ...
}

// âŒ BAD: Too vague
@Test
fun `throws CONFLICT when already issued`() {
    // Given: ì‚¬ìš©ìê°€ ì¿ í°ì„ ê°€ì§€ê³  ìˆìŒ
    // When: ë°œê¸‰ ìš”ì²­
    // Then: ì—ëŸ¬
}
```

**Rule**: Include only values that would change the test outcome if different.

---

## One Behavior Per Test

Each test case must verify **one behavior**. If you're tempted to write multiple unrelated "Then" conditions, split into
separate tests.

```kotlin
// âŒ Bad: Two unrelated behaviors in one test
@Test
@DisplayName("ì£¼ë¬¸ì´ ìƒì„±ë˜ê³  ì‚¬ìš©ì ì£¼ë¬¸ ìˆ˜ê°€ ì¦ê°€í•œë‹¤")
fun `creates order and increments user order count`() {
    // Given: ...
    // When: Create order
    // Then: Order status is PLACED
    // Then: User's orderCount is incremented  â† different behavior
    fail("Not implemented")
}

// âœ… Good: Split into focused tests
@Test
@DisplayName("ì£¼ë¬¸ì´ ìƒì„±ëœë‹¤")
fun `creates order`() {
    // Given: ...
    // When: Create order
    // Then: Order status is PLACED
    fail("Not implemented")
}
```

## Handling Spec Changes

When milestone indicates changes to existing functionality:

1. Read the updated spec section
2. Read existing test file for the affected scope
3. Compare each existing test case against updated spec:
    - Spec unchanged for this case â†’ Keep the case
    - Spec changed affecting this case â†’ Rewrite with updated Given/When/Then
    - Case no longer valid per spec â†’ Remove from output
4. Identify new cases required by updated spec â†’ Add new skeletons

All cases in output use identical skeleton format with `fail("Not implemented")`.

The critical job is **deciding what to test** based on spec-to-test comparison.

## Quality Checklist (Generation)

- [ ] BDD structure is correct (@Nested per behavior, no more than 1 level of nesting)
- [ ] Naming convention is followed (Korean @DisplayName, English method name with `[result] when [condition]`)
- [ ] Every test body contains `fail("Not implemented")`
- [ ] Given/When/Then comments specify concrete values and expected results
- [ ] Verification does not exceed the responsibility of each level
- [ ] No duplicate verification across levels
- [ ] Each test verifies **one behavior** only
- [ ] "Then" describes observable outcomes (state/result/exception), NOT method calls

## Forbidden "Then" Patterns

| âŒ FORBIDDEN                   | âœ… ALLOWED                    |
|-------------------------------|------------------------------|
| `repository.save() is called` | `Balance is 700`             |
| `service.method() is invoked` | `Order status is PLACED`     |
| `verify(mock).method()`       | `Exception is thrown`        |
| `no interaction with X`       | `No order exists for userId` |
| `called N times`              | `Response status is 201`     |
